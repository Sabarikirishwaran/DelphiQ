{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11965025,"sourceType":"datasetVersion","datasetId":7523729}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-cache-dir torch torchvision torchaudio -q\n!pip install --no-cache-dir pytorch-lightning -q\n!pip install --no-cache-dir custatevec-cu12 -q\n!pip install --no-cache-dir lightning pennylane-lightning-gpu -q\n!pip install --no-cache-dir pandas matplotlib -q\n#!pip install \"jax[cuda11_pip]==0.4.28\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:50:30.374947Z","iopub.execute_input":"2025-05-28T11:50:30.375710Z","iopub.status.idle":"2025-05-28T11:50:46.073174Z","shell.execute_reply.started":"2025-05-28T11:50:30.375683Z","shell.execute_reply":"2025-05-28T11:50:46.072338Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport gzip\nimport io\nimport pandas as pd\nimport pennylane.numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\ndef load_weather_data(folder_path='.', datetime_format='%d-%b-%Y %H:%M'):\n    \"\"\"\n    Load all .csv weather files (rainfall/wind) in folder_path.        \n    \"\"\"\n    datasets = {}\n    # Expected headers\n    expected_keywords = ['date', 'time', 'rain', 'wind']\n    \n    for file in glob(os.path.join(folder_path, '*.csv')):\n        name = os.path.basename(file).replace('.csv', '')\n        try:            \n            with open(file, 'rt') as f:\n                lines = f.readlines()\n                            \n            header_idx = 0\n            for idx, line in enumerate(lines):\n                tokens = set(line.strip().lower().split(\" \"))                \n                if any(keyword in tokens for keyword in expected_keywords):\n                    header_idx = idx\n                    break                        \n            \n            # Load csv\n            df = pd.read_csv(\n                io.StringIO(''.join(lines[header_idx:])),\n                dtype=str,\n                low_memory=False\n            )\n            \n            # Parse datetime\n            if 'date' in df.columns and 'time' in df.columns:\n                df['datetime'] = pd.to_datetime(\n                    df['date'] + ' ' + df['time'],\n                    format=datetime_format,\n                    errors='coerce'\n                )\n                df.drop(columns=['date', 'time'], inplace=True)                \n            else:\n                # fallback\n                dt_col = next((col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()), None) \n                df['datetime'] = pd.to_datetime(df[dt_col], format=datetime_format, errors='coerce')                \n                df.drop(columns=[dt_col], inplace=True)\n                        \n            rename_map = {}\n            for c in df.columns:\n                lc = c.lower()\n                if 'rain' in lc: \n                    rename_map[c] = 'rainfall_mm'\n                if 'wind' in lc and 'speed' in lc:\n                    rename_map[c] = 'wind_speed_mps'\n            df.rename(columns=rename_map, inplace=True)\n            df['wind_speed_mps'] = df['wind_speed_mps'].replace({'VRB': None, 'NA': None, 'NaN': None})\n                        \n            df = df[['datetime', 'rainfall_mm', 'wind_speed_mps']].copy()            \n            df = df.dropna(subset=['datetime', 'rainfall_mm', 'wind_speed_mps'])                                \n            df['rainfall_mm'] = pd.to_numeric(df['rainfall_mm'], errors='coerce')\n            df['wind_speed_mps'] = pd.to_numeric(df['wind_speed_mps'], errors='coerce')\n            \n            df = df.sort_values('datetime').reset_index(drop=True)\n            start_date = pd.Timestamp('2019-10-21')\n            df = df[df['datetime'] >= start_date]                \n            print(f\"Weather loaded: {name} ({len(df)} rows)\")\n        \n        except Exception as e:\n            print(f\"Skipping {name}: {e}\")\n    \n    return df\n\ndef load_river_level_data(folder_path='.', river_sites=None, datetime_format='%Y-%m-%d %H:%M:%S'):\n    \"\"\"\n    Load river level csv for specified river_sites.        \n    \"\"\"\n    if river_sites is None:\n        river_sites = ['waikato', 'waipa', '']\n    datasets = {}\n    expected_cols = ['date', 'time', 'wlvalue', 'flvalue']\n    for file in glob(os.path.join(folder_path, '*.csv')) + glob(os.path.join(folder_path, '*.csv')):\n        name = os.path.basename(file)\n        \n        if not any(site.lower() in name.lower() for site in river_sites):\n            continue\n        try:            \n            opener = gzip.open if file.endswith('.gz') else open\n            with opener(file, 'rt') as f:\n                lines = f.readlines()\n            \n            header_idx = 0\n            for idx, line in enumerate(lines):\n                tokens = set(line.strip().lower().replace(',',' ').split())                \n                if any(keyword in tokens for keyword in expected_cols):\n                    header_idx = idx\n                    break\n                                \n            df = pd.read_csv(\n                io.StringIO(''.join(lines[header_idx:])),\n                dtype=str, low_memory=False\n            )            \n                    \n            if 'date' in df.columns and 'time' in df.columns:                \n                df['dt'] = df['date'] + ' ' + df['time']                                \n                df['datetime'] = pd.to_datetime(\n                    df['dt'],\n                    format=datetime_format,\n                    errors='coerce'\n                )                \n                df.drop(columns=['date', 'time', 'dt'], inplace=True)                \n                        \n            df['river_level'] = df['wlvalue'].astype(float)\n            df = df.dropna(subset=['datetime', 'river_level'])            \n            df = df[['datetime', 'river_level']].sort_values('datetime')\n            df = df.set_index('datetime')\n            #resample data hourly\n            df = df.resample('h').ffill()  \n            print(f\"River loaded: {name} ({len(df)} rows)\")\n            datasets[name] = df\n        except Exception as e:\n            print(f\"Skipping river {name}: {e}\")\n    return datasets\n\ndef merge_weather_and_river(weather_df, river_df):\n    \"\"\"\n    Merge weather and river level data on exact datetime match (inner join).    \n    \"\"\"\n    # Ensure both are in datetime64[ns] type\n    weather_df = weather_df.copy()\n    river_df = river_df.copy()    \n    \n    # Inner join on exact datetime match\n    merged = pd.merge(weather_df, river_df, on='datetime', how='inner')\n\n    #print(f\"Merged {len(merged)} rows on datetime match\")\n\n    return merged\n\ndef visualize_merged_data(data, threshold=150, title='Merged Timeseries'):\n    \"\"\"\n    Plot rainfall and river level with threshold line.\n    \"\"\"\n    fig, ax1 = plt.subplots(figsize=(12,6))\n    ax1.plot(data['datetime'], data['rainfall_mm'], label='Rainfall (mm)', color='blue')\n    ax1.set_xlabel('Datetime'); ax1.set_ylabel('Rainfall (mm)', color='blue')\n    ax1.tick_params(axis='y', labelcolor='blue')    \n    \n    ax2 = ax1.twinx()\n    ax2.plot(data['datetime'], data['river_level'], label='River Level (m)', color='green')\n    ax2.set_ylabel('River Level (m)', color='green')\n    ax2.tick_params(axis='y', labelcolor='green')\n    \n    #fig.tight_layout()\n    plt.title(title)\n    fig.legend()\n    plt.show()\n\n# Load data\nweather_data = load_weather_data(folder_path='/kaggle/input/wbc-datasets/rainfall_data/Observations_Hourly_Auckland_Aerodrome_NZAAA_1993Jan01_2025May23.csv')\nriver_data = load_river_level_data(folder_path='/kaggle/input/wbc-datasets/riverlevel_data', river_sites=['waikato','waipa'])\nmerged_data = {}\n\n# Merge matching datasets\nfor rname, rdata in river_data.items():\n    merged_data[rname] = merge_weather_and_river(weather_data, rdata)\n\nkey = next(iter(merged_data))\ndf_merge = merged_data[key]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:49:22.273434Z","iopub.execute_input":"2025-05-28T11:49:22.273679Z","iopub.status.idle":"2025-05-28T11:49:22.881879Z","shell.execute_reply.started":"2025-05-28T11:49:22.273657Z","shell.execute_reply":"2025-05-28T11:49:22.880729Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_133/706451754.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_fn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooleanFn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueuing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueuingManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mwrap_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NumPy with automatic differentiation support, provided by Autograd and PennyLane.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/operation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mABCCaptureMeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_operator_primitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpand_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueuing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueuingManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/capture/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mswitches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcapture_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaptureMeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCaptureMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcapture_operators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_operator_primitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/capture/switches.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mhas_jax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mhas_jax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# See PEP 484 & https://github.com/google/jax/issues/7570\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from jax._src.core import (\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mAbstractToken\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractToken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mAbstractValue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDTypeLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStrictABC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransfer_guard_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mversion_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m version = check_jaxlib_version(\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0mjax_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mjaxlib_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36mcheck_jaxlib_version\u001b[0;34m(jax_version, jaxlib_version, minimum_jaxlib_version)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_jaxlib_version\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_jax_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;34mf'jaxlib version {jaxlib_version} is newer than and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34mf'incompatible with jax version {jax_version}. Please '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: jaxlib version 0.5.1 is newer than and incompatible with jax version 0.4.28. Please update your jax and/or jaxlib packages."],"ename":"RuntimeError","evalue":"jaxlib version 0.5.1 is newer than and incompatible with jax version 0.4.28. Please update your jax and/or jaxlib packages.","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Visualize\nfor key, df_merge in merged_data.items():\n    X, y = generate_windowed_dataset(df_merge)\n    visualize_merged_data(df_merge, title=key)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(merged_data.keys())\nmerged_data['RiverLevel-WaikatoRiver-HamiltonTrafficBr-1stJan1993-23rdMay2025.csv']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport pandas as pd\nimport pennylane as qml\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport csv\nfrom tqdm import trange\nfrom torch.utils.data import TensorDataset, DataLoader\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\nnb_reuploading = 3\nlookback = 7  # window size\nnb_qubit_reupload = 3\n\nnum_variational = 3\nnb_epoch = 1\nlr = 0.01\nbatch_size = 32\n\ndev_reupload = qml.device(\"default.qubit\", wires=nb_qubit_reupload, shots=None)\n\ndef encoding_layer(params_encoding, x, lookback, nb_qubit):        \n    x = x.reshape(-1, lookback, nb_qubit_reupload)\n    #print(\"params_encoding.shape, x.shape\", params_encoding.shape, x.shape)\n    \n    rotation_gates = [qml.RX, qml.RY, qml.RZ]\n    for q in range(nb_qubit):\n        for j in range(lookback):            \n            gate = rotation_gates[j % len(rotation_gates)]            \n            gate(params_encoding[q,j] * x[:,j,q], wires=q)\n\ndef variational_layer(params_variational, lookback, nb_qubit, num_variational):\n    #print(\"params_variational.shape\", params_variational.shape)\n    rotation_gates = [qml.RX, qml.RY, qml.RZ]\n    for q in range(nb_qubit):\n        for k in range(num_variational):\n            gate = rotation_gates[k % len(rotation_gates)]                        \n            gate(params_variational[q, k], wires=q)\n\n@qml.qnode(dev_reupload, interface=\"torch\", diff_method=\"backprop\")\ndef quantum_circuit_reupload(x, params):\n    params_enc, params_var, ent_wieghts = params        \n    for i in range(nb_reuploading):\n        encoding_layer(params_enc[i], x, lookback, nb_qubit_reupload)\n        variational_layer(params_var[i], lookback, nb_qubit_reupload, num_variational)\n\n    qml.StronglyEntanglingLayers(weights=ent_wieghts, wires=range(nb_qubit_reupload))    \n    #return  [qml.expval(qml.PauliZ(i)) for i in range(nb_qubit_reupload)]\n    return qml.expval(qml.PauliZ(0))\n\ndef prediction_accuracy(y_pred, y_true, tolerance=0.1):\n    correct = torch.sum(torch.abs(y_pred - y_true) < tolerance)\n    return 100 * correct / len(y_true)\n\ndef split_data(data, test_ratio, lookback, target_col):\n    X, y = generate_windowed_dataset(data, lookback=lookback, target_col=target_col)\n    split = int(len(X) * (1 - test_ratio))\n    return X[:split], y[:split], X[split:], y[split:]\n\ndef plot_metrics(loss_hist, acc_hist, grad_norm_hist, name):\n    epochs = range(1, len(loss_hist)+1)\n    plt.figure()\n    plt.plot(epochs, loss_hist, label=\"Test Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(f\"{name}: Test Loss over Epochs\")\n    plt.legend()\n    plt.savefig(f\"{name}_loss_plot.png\", dpi=300)\n    plt.close()\n\n    plt.figure()\n    plt.plot(epochs, acc_hist, label=\"Test Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(f\"{name}: Test Accuracy over Epochs\")\n    plt.legend()\n    plt.savefig(f\"{name}_accuracy_plot.png\", dpi=300)\n    plt.close()\n\n    plt.figure()\n    plt.plot(epochs, grad_norm_hist, label=\"Gradient Norm\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"L2 Norm\")\n    plt.title(f\"{name}: Gradient Norm over Epochs\")\n    plt.legend()\n    plt.savefig(f\"{name}_gradnorm_plot.png\", dpi=300)\n    plt.close()\n\ndef plot_predictions(y_true, y_pred, name):\n    plt.figure(figsize=(12, 5))\n    plt.plot(y_true, label=\"Ground Truth\", linewidth=2)\n    plt.plot(y_pred, label=\"Predictions\", linestyle=\"--\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Normalized Value\")\n    plt.title(f\"{name}: Predictions vs Ground Truth\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f\"{name}_prediction_plot.png\", dpi=300)\n    plt.close()\n\ndef train_and_eval(model, params_init, X_tr, y_tr, X_te, y_te, name, epochs, lr):\n    params = [p.clone().detach().requires_grad_(True) for p in params_init]\n    opt = torch.optim.RMSprop(params, lr=lr)\n    loss_hist, acc_hist, grad_norm_hist = [], [], []\n    param_count = sum(p.numel() for p in params if p.requires_grad)\n    print(f\"Trainable parameters: {param_count}\")    \n    mse_loss = torch.nn.MSELoss()\n    train_ds = TensorDataset(X_tr, y_tr)    \n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=0)\n    \n\n    with open(f\"{name}_metrics.csv\", \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\"epoch\", \"test_loss\", \"test_acc\", \"grad_norm\"])\n\n        for ep in trange(epochs, desc=f\"Training {name}\"):\n        #for ep in range(epochs):\n            for X_batch, y_batch in train_loader:\n                #rint(\"X_batch, y_batch shapes\", X_batch.shape, y_batch.shape)\n                opt.zero_grad()                \n                preds = model(X_batch, params)\n                #print(\"preds.shape\", preds.shape)\n                #preds = torch.stack(preds) if isinstance(preds, list) else preds                \n                loss = mse_loss(preds, y_batch)\n                loss.backward()\n                            \n                total_norm = 0.0\n                for p in params:\n                    if p.grad is not None:\n                        param_norm = p.grad.data.norm(2)\n                        total_norm += param_norm.item() ** 2\n                grad_norm = total_norm ** 0.5\n                \n                opt.step()\n\n            with torch.no_grad():                   \n                preds_t = model(X_te, params)\n                loss_t = mse_loss(preds_t, y_te).item()\n                acc_t = prediction_accuracy(preds_t, y_te).item()\n\n            loss_hist.append(loss_t)\n            acc_hist.append(acc_t)\n            grad_norm_hist.append(grad_norm)\n\n            writer.writerow([ep+1, loss_t, acc_t, grad_norm])\n            f.flush()\n\n    plot_metrics(loss_hist, acc_hist, grad_norm_hist, name)\n    torch.save([p.detach() for p in params], f\"{name}_trained_params.pt\")\n\n    with torch.no_grad():\n        #preds_final = torch.stack([model(params, x) for x in X_te])\n        preds_final = model(X_te, params)\n        with open(f\"{name}_predictions.csv\", \"w\", newline=\"\") as f_pred:\n            writer = csv.writer(f_pred)\n            writer.writerow([\"Index\", \"Actual\", \"Predicted\"])\n            for i, (true_val, pred_val) in enumerate(zip(y_te, preds_final)):\n                writer.writerow([i, true_val.item(), pred_val.item()])\n        plot_predictions(y_te.numpy(), preds_final.cpu().numpy(), name)    \n\ndef draw_quantum_circuit():\n    # Dummy input: [batch_size, lookback, nb_qubit] → use [1, lookback, nb_qubit] then squeeze to [lookback, nb_qubit]\n    batch_size = 32\n    dummy_x = torch.rand((batch_size, lookback, 3), dtype=torch.float64)\n\n    # Dummy parameters with correct shape\n    dummy_params = [\n        torch.ones((nb_reuploading, nb_qubit_reupload, lookback), dtype=torch.float64) * np.pi,\n        torch.ones((nb_reuploading, nb_qubit_reupload, num_variational), dtype=torch.float64) * np.pi,\n        torch.ones(qml.StronglyEntanglingLayers.shape(n_layers=1, n_wires=nb_qubit_reupload), dtype=torch.float64) * np.pi\n    ]\n\n    # Draw the circuit    \n    fig, ax = qml.draw_mpl(quantum_circuit_reupload, decimals=2, style=\"pennylane\")(dummy_x, dummy_params)\n    plt.show()\n\ndata = merged_data['RiverLevel-WaikatoRiver-HamiltonTrafficBr-1stJan1993-23rdMay2025.csv'].iloc[-365:].copy() # Due to limited compute - trainning on last one year of data \nprint(f\"Data shape: {data.shape}\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndraw_quantum_circuit()\nX_tr_np, y_tr_np, X_te_np, y_te_np = split_data(data=data, test_ratio=0.2, lookback=lookback, target_col='river_level')\nX_tr = torch.tensor(X_tr_np, dtype=torch.float64).to(device)\ny_tr = torch.tensor(y_tr_np, dtype=torch.float64).to(device)\nX_te = torch.tensor(X_te_np, dtype=torch.float64).to(device)\ny_te = torch.tensor(y_te_np, dtype=torch.float64).to(device)\n\nent_shape = qml.StronglyEntanglingLayers.shape(n_layers=1, n_wires=nb_qubit_reupload)\n\nparams_init_reupload = [\n    torch.full((nb_reuploading, nb_qubit_reupload, lookback), np.pi, dtype=torch.float64, requires_grad=True).to(device),\n    torch.full((nb_reuploading, nb_qubit_reupload, num_variational), np.pi, dtype=torch.float64, requires_grad=True).to(device),\n    torch.full((ent_shape), np.pi, dtype=torch.float64, requires_grad=True).to(device)\n]\n\ntrain_and_eval(quantum_circuit_reupload, params_init_reupload, X_tr, y_tr, X_te, y_te, \"QRU_ent\", nb_epoch, lr)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
